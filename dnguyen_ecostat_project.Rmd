---
title: "Deterministic and stochastic effects of food quality on extinction time"
author: "David Nguyen"
date: "October 20, 2020"
output: 
  html_document:
    code_folding: hide
# output:
#   word_document: default
bibliography: nres803.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
library(tidyverse)
library(readxl)
library(broom.mixed)
library(nlme)
```

```{r munge_data, include = FALSE}
# get names of sheets that contain pop data (not including T15-8 for now)
sheet_names <- excel_sheets("weevil_data/pop_dynamics_expt_data.xlsx")
sheet_pops <- sheet_names[1:5]
pct_peanut_shells <- c(0, 0.03, 0.05, 0.10, 0.15)

# create new colnames
npop <- 10
date_cols <- c("days", "date")
demo_cols <- unlist(lapply(1:npop,
       function(i)
         c(paste0("m_alive_",i),
           paste0("f_alive_",i),
           paste0("total_alive_", i),
           paste0("m_dead_",i),
           paste0("f_dead_",i),
           paste0("total_dead_",i))))
treatment_cols <- c("m_added", "f_added", "pellets", "noclue", "treatment")

# read-in and reformat all population data sheets

list_dfs <- vector("list", length = length(sheet_pops)) # init list to store each df

# loop to read and reformat
for (i in seq_along(sheet_pops)) {
  df_now <-
    read_excel("weevil_data/pop_dynamics_expt_data.xlsx",
               skip = 3,
               sheet = sheet_pops[i]) %>%
    mutate(treatment = pct_peanut_shells[i])
  
  # assign new colnames
  names(df_now) <-
    c(date_cols, demo_cols, treatment_cols) # should include check to make sure all data sheets have same format
  
  # T15 has weird ??? in a col. CHange to NA and convert col to numeric
  if (i == 5) {
    df_now$m_alive_8 <-
      df_now %>% 
      mutate_at(vars('m_alive_8'), ~na_if(., '???')) %>%
      pull(m_alive_8) %>%
      as.numeric()
  }
  
  # make data longer for plotting
  df_long <- df_now %>%
    select(-pellets,-noclue) %>% # always 2 pellets a day, and drop noclue as well as the num. added
    filter(!is.na(days)) %>%  # drop empty bottom two rows (included when reading due to sum(pellets) in spread sheet)
    pivot_longer(
      -c(days, date, m_added, f_added,treatment),
      names_sep = "_",
      names_to = c("sex", "status", "replicate"),
      values_to = "count"
    ) %>%
    # original data file did not have totals computed for all days
    # create new df with totals for all days
    filter(sex != "total" , status == "alive") %>%
    group_by(date, replicate) %>%
    mutate(total = sum(count, na.rm = TRUE)) %>% # females were not observed after first few days
    ungroup()
  
  # save to list
  list_dfs[[i]] <- df_long
}

full_df <- bind_rows(list_dfs)

full_df <- full_df %>% mutate(replicate = as.numeric(replicate))
#full_df$treatment <- as_factor(full_df$treatment) # for proper facetting when plotting. Should convert to numeric instead.
```

```{r clean_for_analysis, warning = FALSE}
# verify that "total" is the same regardless of sex (which wasn't actually distinguished during expt)
# all.equal( filter(full_df, sex == "m") %>% pull(total), filter(full_df, sex == "f") %>% pull(total) )
weevil <-
  full_df %>%
  filter(sex == "m",  # remove duplicate rows of "total"
         is.na(m_added)) %>% # Only include data after initialization complete
  select(days, treatment, replicate, total) %>% # drop all unimportant cols
  filter(treatment != 0.03) # drop 3 % shell treatment, since it is diff length and was only initialized 20 days instead of 32 like others

# set all "total" values to NA after extinction
# I will define exinction as the last time the cumulative population total increases
# e.g., take cumsum for all trt X rep combinations, then get index where cumsum(total) == max(cumsum), set all total values afterwards to NA

weevil <- 
  weevil %>% 
  group_by(treatment, replicate) %>%
  mutate(cumtotal = cumsum(total), 
         max_cumtotal = max(cumtotal)) %>%
  rowwise() %>%
  mutate(last_day = ifelse( (cumtotal == max_cumtotal) && (total == 0), days, NA)) %>%
  group_by(treatment, replicate) %>%
  mutate(last_day = min(last_day, na.rm = TRUE)) %>%
  mutate(total = ifelse(days > last_day, NA, total)) %>%
  mutate(last_day = ifelse(last_day == Inf, NA, last_day)) %>%
  # get next total, ln(abundance + 1), compute r, and make a new treatment col that is a factor
  mutate(next_total = lead(total),
         l_total = log(total + 1),
         l_next_total = log(next_total + 1),
         r = log((next_total + 1)/(total + 1)),
         ftreatment = factor(treatment, levels = c("0", "0.05", "0.1", "0.15")),
         freplicate = factor(replicate, levels = as.character(1:10)),
         time = (days - 32)/4) %>%
  unite(c("ftreatment", "replicate"), col = "rep_trt", remove = FALSE)
```

```{r define_sim_gomp}
sim_log_gomp <- function (xinit,     # initial log population size
                     lambda, # population growth rate,
                     b,      # density dependence
                     sd_proc, # process noise: N(0, sd_proc)
                     tfinal,
                     nsim,
                     replicate,
                     ftreatment) {
  
  # init storage list for all simulation
  sim_list <- vector("list", length = nsim)
  
  for (i in seq_along(sim_list)) {
    # init storage for current simulation
    log_x <- vector("numeric", length = tfinal)
    log_x[1] <- xinit
    
    # sim population dynamics
    for (j in 2:tfinal) {
      proc_error <- rnorm(n = 1, mean = 0, sd = sd_proc)
      log_x[j] <- lambda + b * log_x[j-1] + proc_error
    }
    # save current simulation
    sim_list[[i]] <- (tidyr::tibble(time = 1:tfinal,
                                    log_x = log_x,
                                    N = exp(log_x),
                                    lambda = lambda,
                                    b_ = b,
                                    sd_proc = sd_proc,
                                    replicate = replicate,
                                    ftreatment = ftreatment))
  } 
  out <- dplyr::bind_rows(sim_list, .id = "sim")
  return(out)
}
```

# Introduction

Habitat degredation a major threat to animal populations [@sala_global_2000]. As a consequence, food quality may also be reduced which are known to have strong impacts on individual and population level growth [@awmack_host_2002; @griffen_effects_2008]. Poor food quality typically decrease fecundity and increase development time which may, in turn, reduce population level growth rates and carrying capacity. In experimental studies, the effects of food quality on population parameters are quantified by including food quality as a covariate for estimating population parameters; however, to the best of my knowledge, the effect of food quality on the variability of population parameters is not routinely quantified despite clear signals of food-quality specific variability in experimental data [cf. figure 2 in @griffen_effects_2008].

Both deterministic and stochastic forces drive population dynamics and extinction risk [@bjornstad_noisy_2001; @fung_partitioning_2019]. For example, low population growth rates are a deterministic driver of population declines whereas variability in population growth rates is a stochastic driver of increased extinction risk [@vucetich_population_2000]. Appropriately modeling the sources of stochasticity is important for accurate modeling of population dynamics and extinction risk [@melbourne_extinction_2008]. Therefore, when modeling the effect of a food quality on population growth it may be important to consider both fixed and random effects for accurate assessments of extinction risk.

The main objective of this analysis is to identify the relative contributions of the deterministic and stochastic impact of resource quality on extinction time. Food quality may impact populations deterministically by affecting population growth rate and/or carrying capacity and stochastically by increasing variability of environmental noise. I will use existing time-series data of southern cowpea weevil (*Callosobruchus maculatus*) populations subjected to food quality treatments (M. Dyck unpublished). To quantify the contribution of deterministic and stochastic effects of food quality, I will fit a set of population models to the bean weevil data that allow for:

1. Growth rate and density dependence to vary with food quality;
2. An additive effect of food quality on environmental noise;
3. Both 1 and 2.

The models will be compared by AIC and goodness of fit will be assessed by comparing the extinction frequency and extinction time distribution of the observed weevil populations and simulations from fitted models. 

# Materials and methods

### Bean weevil population data

```{r plot_all}
full_df %>%
  ggplot(aes(x = days, y = total, group = replicate, col = as.factor(replicate) )) +
  geom_line() + 
  facet_wrap(~treatment) +
  theme_light() +
  theme(legend.position = "none") +
  scale_x_continuous(breaks = seq(0, 650, by = 100)) +
  scale_y_continuous(breaks = seq(0, 50, by = 10)) +
  labs(title = "Bean weevil populations over time",
       caption = "For each plot, weevils were fed pellets with a different proportion of peanut shell additive.\nEach color is a different replicate.",
       y = "Bean weevil count",
       x = "Time (days)")

```

The quality of food provided to the weevils was experimentally manipulated by manufacturing artificial bean pellets made from ground black-eyed pea powder and varying percentages of powdered peanut shells (0, 3, 5, 10, and 15 %). Larger percentages of peanut shell simulate lower food quality.  To initialize each replicate population, two males and two females were added every four days for the first 28 days of the experiment. After this initialization, two fresh bean pellets were added weekly without any further addition of adults. There were 10 replicate populations allocated to each treatment resulting in a total of 50 population time-series. Populations were maintained until the populations crashed or were stopped after 632 days (the 3 % peanut shell treatment was started later and ran for 400 days). A complete census of adult bean weevils was conducted every four days.

### Model structure and fitting

The discrete-time stochastic Gompertz model will be fit to the remainder of weevil abundances after the initialization phase is removed. The Gompertz model is commonly used for modeling ecological populations [@dennis_estimating_2006]. The models will be estimated using a one-step fitting procedure which assumes that there is no observation noise [@bolker_ecological_2008]; this is an appropriate assumption since the populations were completely censused at each time point. 

The full model is as follows:

$$y_{t+1,i,j} = a_i + b_i y_t + c_i + d_j + \epsilon_{t,i,j} \\
\epsilon_{t,i,j} \sim N(0,\sigma_0^2)\\
c_i \sim N(0, \sigma_i^2)\\
d_{ij} \sim N(0, \sigma_{rep}^2)$$

Where $\ln(N_{t,i,j} + 1) = y_{t,i,j}$ is the log-population abundance at times $t$ for peanut shell percentages $i = 0, 3, 5, 10, 15$ and replicates $j = 1, \ldots, 10$. The deterministic (fixed-effect) of food quality operates on weevil populations are represented by the population growth rate ($a_i$) and the strength of density dependence ($b_i$). The stochastic (random-effect) of food quality on weevil populations are represented by a food-specific increase in variance of population growth ($c_i$) from time step $t$ to $t+1$. The random effect of replicate and random error are denoted $d_j$ and $epsilon_{t,i,j}$ respectively.

The model that includes only the deterministic impact of food quality is obtained by dropping the $c_i$ term. The model for only the stochastic impact of food quality is obtained by estimating a common population growth rate ($a$) and density dependence coefficient ($b$) across all food quality treatments.

<!-- A likely short-coming of the models I will fit is that the models only include the effect of the previous log-population abundance on the size of the next log-population abundance. However, the sampling frequency (every four days) is much shorter than the generation times of the weevils which range between 20 and 60 days depending on resource quality. A more careful analysis would involve assessing the number of lagged population sizes to capture the dynamics of the population data. -->
<!-- * assumes process noise only (ok because population are completely censused at each observation time; Ben Bolker book) -->
<!-- * higher-order lags can be collected into error term. Shaky assumption, especially considering that larvae and eggs are unobserved. A suitable approach would be to try using additional lagged terms which can be justified by Takens theorem (see ellner and turchin paper). -->

<!-- ### Model set -->

<!-- Full model -->

### Estimating carrying capacity

The expected log-abundance is $E(X_{\infty,i}) = a_i/(1-b_i)$, the variance of the stationary distribution of the log population is $V(X_{\infty,i}) = \sigma^2/(1-b_i)$, and the mean of the log-normal distribution of abundance is $E(N_{\infty,i}) = \exp[E(X_{\infty,i}) + V(X_{\infty,i})/2]$ [@dennis_estimating_2006].

### Evaluating goodness of fit

Assessing the goodness of fit for noisy populations is challenging because sensitivity to small changes in initial conditions and process noise may generate very different population trajectories [@wood_statistical_2010]. To avoid these issues, I will assess goodness of fit by comparing summary statistics of the observed data to the same summary statistics computed for simulated output from the fitted Gompertz models. For each fitted model, I will repeatedly simulate the model for the same number of time steps the experimental populations were observed and the same number of replicates used in the experiment. The summary statistics I will use are: (1) the frequency of populations that became extinct; (2) the distribution of time to extinction, conditioned on having observed extinctions.

<!-- Statistical probes  ala Simon Wood (2010) -->

<!-- * Use ar(1) and extinction time as statistical summaries -->
<!-- * maybe use rolling mean and variance too? -->

```{r plot_obs_extinction_time}
weevil %>%
  group_by(treatment, replicate) %>%
  slice(1) %>%
  summarise(last_day) %>%
  group_by(treatment) %>%
  mutate(mean_time = mean(last_day, na.rm = TRUE),
         treatment = as.factor(treatment)) %>%
  ggplot() +
  geom_histogram(aes(x = last_day, group = treatment)) +
  geom_vline(aes(xintercept = mean_time, group = treatment), size = 1.5, linetype = 2) +
  facet_wrap(~treatment) +
  labs(title = "Distribution of observed extinction times")
```

# Results

### Model comparison

```{r fit_models}
# treatment specific growth rate and density dependnece
# homogenous variance
m1 <- gls(l_next_total ~ l_total*ftreatment - 1, 
    data = weevil, 
    method = "ML",
    na.action=na.omit)

# common growth rate and density dependnece
# treatment specific variance
m2 <- 
  gls(l_next_total ~ l_total - 1, 
    data = weevil, 
    weights = varIdent(form = ~1 | ftreatment), # factor specific residual variance
    method = "ML",
    na.action=na.omit)

# treatment specific growth rate and density dependnece
# treatment specific variance
m3 <- 
  gls(l_next_total ~ l_total*ftreatment -1, 
    data = weevil, 
    weights = varIdent(form = ~1 | ftreatment), # factor specific residual variance
    method = "ML",
    na.action=na.omit)

# treatment specific growth rate and density dependnece
# treatment specific variance
# random intercept of rep:trt (which is replicate nested in treatment)
m4 <- lme(l_next_total ~ l_total*ftreatment - 1, 
    random = ~ 1 | rep_trt,
    data = weevil, 
    weights = varIdent(form = ~1 | ftreatment), # factor specific residual variance
    method = "ML",
    na.action=na.omit) # ignore na values

# treatment specific growth rate and density dependnece
# treatment specific variance
# random intercept and slope of rep:trt (which is replicate nested in treatment
m5 <- lme(l_next_total ~ l_total*ftreatment - 1, 
    random = ~ 1 + ftreatment| rep_trt,
    data = weevil, 
    weights = varIdent(form = ~1 | ftreatment), # factor specific residual variance
    method = "ML",
    na.action=na.omit) # ignore na values
```

```{r eval = FALSE}
m3_drop8 <- 
  gls(l_next_total ~ l_total*ftreatment -1, 
    data = weevil %>% filter(!(ftreatment == 0.15 & replicate == 8)), 
    weights = varIdent(form = ~1 | ftreatment), # factor specific residual variance
    method = "ML",
    na.action=na.omit)

summary(m3_drop8)
```


```{r aic_table}
AIC(m1, m2, m3, m4) %>%
  mutate(delta = AIC - min(AIC),
         weight = exp(-delta/2),
         weight = weight/sum(weight)) %>%
  add_column(model = c("model 1", "model 2", "model 3", "model 4")) %>%
  select(model, df, AIC, delta, weight) %>%
  knitr::kable(digits = 3)
```

```{r AIC_5}
AIC(m1, m2, m3, m4, m5) %>%
  mutate(delta = AIC - min(AIC),
         weight = exp(-delta/2),
         weight = weight/sum(weight)) %>%
  add_column(model = c("model 1", "model 2", "model 3", "model 4", "model 5")) %>%
  select(model, df, AIC, delta, weight) %>%
  knitr::kable(digits = 3)
```

```{r}
# get coef from m4
coef(m4) %>%
  as_tibble(rownames = "treatment_replicate") %>%
  separate(treatment_replicate, sep = "_", into = c("treatment", "replicate"))
```


```{r}
m3_aug <- 
  augment(m3, weevil) %>%
  rename(residuals = .resid, fitted = .fitted)

# try to calculate factor-specific residual SE
df_m3 <- 12 # residual df (I think??? Not sure how this works with factor specific var) 

m3_aug %>%
  group_by(ftreatment) %>%
  mutate(sd_resid = sd(residuals), # directly calculate sd
         sq_resid = sum(residuals^2),
         nobs = n()) %>%
  mutate(se_resid = sqrt(sq_resid/ (nobs - df_m3))) %>% # calculate sqrt(SSE/df_error)
  summarize(sd_resid, se_resid) %>%  
  slice(1) # they are almost the same thing?
  
```

```{r confidence_int}
m3_int <- intervals(m3)
m3_int <- m3_int$coef %>%
  as_tibble(rownames = "coefficient") %>%
  mutate(parameter_sym = case_when(str_detect(coefficient, "l_total") ~ "b",
                                 str_detect(coefficient, "ftreatment") ~ "a",
                                 TRUE ~ coefficient),
         parameter = case_when(parameter_sym == "a" ~ "population growth rate (a)",
                               parameter_sym == "b" ~ "density dependence (b)")) %>%
  mutate(treatment = str_remove_all(coefficient, "[[:alpha:]|:|_]"), # keep only numbers and decimal point
         treatment = ifelse(treatment == "", "0", treatment),
         treatment = factor(treatment, levels = c("0", "0.05","0.1","0.15"))) %>%
  mutate(`estimate (95 % CI)` = paste(round(est.,3), " (", round(lower,3), ", ", round(upper,3), ")"))

m3_int %>% select(treatment, parameter, `estimate (95 % CI)`) %>%
  pivot_wider(names_from = parameter, values_from = `estimate (95 % CI)`) %>%
  select(1, 3, 2) %>%
  knitr::kable(caption = "Parameter estimates for model 3: treatment specific variance")
```


```{r get_parms}
# get treatment specific sd of residuals
# trt_resid is the sd of the residual
# std_resid is the ratio of group-specific sd that is reported by summary(pop_gls_trt)
var_est_trt <-
  augment(m3) %>%
  group_by(ftreatment) %>%
  mutate(trt_resid = sd(.resid)) %>%
  slice(1) %>%
  ungroup() %>%
  mutate(std_resid = trt_resid/min(trt_resid)) %>%
  summarize(trt_resid, std_resid) %>%
  add_column(ftreatment = as.factor(c(0, 0.05, 0.1, 0.15)) )

# extract parameter estimates from top model
parm_est <- tidy(m3) %>% add_column(ftreatment = as.factor(c(0,0,0.05,0.1,0.15,0.05,0.1,0.15)),
                                 parameter = c(c("b","a"),c("a","a","a"),c("b","b","b")) ) %>%
  select(parameter, ftreatment, estimate) %>%
  pivot_wider(names_from = parameter, values_from = estimate)

# replicate parm_est 10 times (# of replicates) so that I can join it to other dfs
#parm_est <- purrr::map_dfr(seq_len(10), function(x) parm_est) 

# get initial log population sizes for all pops
# and join to var_est
init_pop <-
  weevil %>%
  group_by(ftreatment, replicate) %>% 
  mutate(tfinal = (last(days) - first(days)) / 4) %>% # divide by 4 because weevils were counted every 4 days
  filter(days == first(days)) %>%
  group_by(ftreatment) %>%
  select(ftreatment, replicate, l_total, tfinal) %>% 
  full_join(var_est_trt, by = "ftreatment")

# data frame with all initial value and parms for simulations
init_df <- inner_join(init_pop, parm_est)
```

```{r calc_K}
nobs <- weevil %>% filter(!is.na(l_total),!is.na(l_next_total)) %>% group_by(treatment) %>% summarize(nobs = n()) %>% 
  rename(ftreatment = treatment) %>% mutate(ftreatment = as.factor(ftreatment))

K_m3 <- parm_est %>% inner_join(nobs) %>% inner_join(var_est_trt) %>%
  # compute mean and var of log-population and 95 % CI
  mutate(mean_logK = a/(1-b),
         trt_var = trt_resid^2,
         var_logK = trt_var/(1-b),
         upr_logK = mean_logK + 2*sqrt(var_logK),
         lwr_logK = mean_logK - 2*sqrt(var_logK),
         mean_logK_lwr = mean_logK - 1.96*sqrt(var_logK/nobs),
         mean_logK_upr = mean_logK + 1.96*sqrt(var_logK/nobs)) %>%
  # compute mean and var of original scale population         
  mutate(log_mean_K = mean_logK + var_logK/2,
         mean_K = exp(log_mean_K),
         median_k = exp(mean_logK)) %>%
  # compute 95 % CI
  mutate(se_K = sqrt(trt_var/nobs + (trt_var^2 / 2* (nobs - 1)) ), # cox's method
         log_mean_K_lwr = log_mean_K - 1.96 * se_K,
         mean_K_lwr = exp(log_mean_K_lwr),
         log_mean_K_upr = log_mean_K + 1.96 * se_K,
         mean_K_upr = exp(log_mean_K_upr))

K_m3 %>%
  ggplot(aes(x = ftreatment)) +
  geom_point(aes(y = log_mean_K)) +
  geom_errorbar(aes(ymin = log_mean_K_lwr, ymax = log_mean_K_upr))

K_m3 %>%
  ggplot(aes(x = ftreatment)) +
  geom_point(aes(y = mean_logK), size = 2) +
  geom_errorbar(aes(ymin = mean_logK_lwr, ymax = mean_logK_upr), width = 0.5) +
  geom_errorbar(aes(ymin = lwr_logK, ymax = upr_logK), col = "red", width = 0) +
  geom_hline(yintercept = log(1), linetype = 2, size = 1.5) +
  labs(title = "Estimated log carrying capacity",
       caption = "red lines denote E(K) +/- 2sd(K)\nhorizontal dashed line is extinction threshold (ln(1))",
       x = "Percent peanut shell",
       y = "Log Carrying capacity (95 % CI)")
```


# simulations with estimated parameters


```{r}
sims <- lapply(1:nrow(init_df), function(x)
  sim_log_gomp(xinit = unlist(init_df[x, "l_total"]), 
             lambda = unlist(init_df[x, "a"]), 
             b = unlist(init_df[x,"b"]), 
             sd_proc = unlist(init_df[x,"trt_resid"]), 
             tfinal = unlist(init_df[x,"tfinal"]), 
             nsim = 5,
             replicate = unlist(init_df[x,"replicate"]),
             ftreatment = unlist(init_df[x,"ftreatment"]))
  ) %>%
  bind_rows()

sims %>% unite("rep_sim",c("replicate", "sim"), remove = FALSE) %>%
  ggplot() +
  geom_line(aes(x = time*4 - 3, y = N, group = rep_sim), col = "red", alpha = 0.5) +
  geom_line(data = weevil, mapping = aes(x = days - 32, y = total, group = replicate), alpha = 0.7) +
  facet_wrap(~ftreatment)
```

```{r}
filter(sims, ftreatment == 0) %>%
  ggplot() +
  geom_line(aes(x = time*4, y = N, group = interaction(replicate,sim) ), col = "red", alpha = 0.5) +
  geom_line(data = filter(weevil, ftreatment == 0), mapping = aes(x = days - 32, y = total, group = replicate)) +
  facet_wrap(~replicate)
```


```{r}
sims_big_init <- lapply(1:nrow(init_df), function(x)
  sim_log_gomp(xinit = unlist(init_df[x, "l_total"]),
             lambda = unlist(init_df[1, "a"]), 
             b = unlist(init_df[1,"b"]), 
             sd_proc = unlist(init_df[x,"trt_resid"]), 
             tfinal = unlist(init_df[x,"tfinal"]), 
             nsim = 1,
             replicate = unlist(init_df[x,"replicate"]),
             ftreatment = unlist(init_df[x,"ftreatment"]))
  ) %>%
  bind_rows()

sims_big_init %>%
  ggplot() +
  geom_line(aes(x = time*4, y = N, group = replicate),, col = "red", alpha = 0.5) +
  #geom_line(data = weevil, mapping = aes(x = days - 32, y = total, group = replicate), alpha = 0.3) +
  facet_wrap(~ftreatment)
```


```{r acf, eval = FALSE}
# need to write code to extract lag(1) acf
acf1 <- sims %>% filter(ftreatment == 0, replicate == 1, sim == 1) %>% pull(N) %>% acf(plot = FALSE, lag = 1)
acf1$acf[2]
```


```{r}
augment(m3) %>%
  rename(fitted = .fitted, residuals= .resid) %>%
  group_by(ftreatment) %>%
  mutate(var_resid = var(residuals),
         resid_lwr = -1.96*var_resid,
         resid_upr = 1.96*var_resid) %>%
  ggplot(aes(x = as.factor(replicate), y = residuals)) +
  geom_boxplot() +
  geom_jitter(aes(col = ftreatment, shape = ftreatment),alpha = 0.4)  +
  geom_hline(yintercept = 0, linetype = 2, size = 1.5, alpha = 0.5) +
  coord_flip() +
  labs(title = "Residuals for ML estimated model",
       col = "treatment", shape = "treatment",
       x = "treatment x replicate") +
  facet_wrap(~ftreatment)
```

### Model diagnostics

```{r m3_resids, message=FALSE, warning = FALSE}
m3_aug %>%
  filter(ftreatment == 0) %>%
  ggplot(aes(x = fitted, y = residuals)) +
  geom_point() + 
  geom_smooth() +
  geom_hline(yintercept = 0, linetype = 2) +
  facet_wrap(~replicate) +
  labs(title = "Residual plot for one-step-ahead model",
       subtitle = "0 % shell")

m3_aug %>%
  filter(ftreatment == 0.05) %>%
  ggplot(aes(x = fitted, y = residuals)) +
  geom_point() + 
  geom_smooth() +
  geom_hline(yintercept = 0, linetype = 2) +
  facet_wrap(~replicate) +
  labs(title = "Residual plot for one-step-ahead model",
       subtitle = "5 % shell")

m3_aug %>%
  filter(ftreatment == 0.1) %>%
  ggplot(aes(x = fitted, y = residuals)) +
  geom_point() + 
  geom_smooth() +
  geom_hline(yintercept = 0, linetype = 2) +
  facet_wrap(~replicate) +
  labs(title = "Residual plot for one-step-ahead model",
       subtitle = "10 % shell")

m3_aug %>%
  filter(ftreatment == 0.15) %>%
  ggplot(aes(x = fitted, y = residuals)) +
  geom_point() + 
  geom_smooth() +
  geom_hline(yintercept = 0, linetype = 2) +
  facet_wrap(~replicate) +
  labs(title = "Residual plot for one-step-ahead model",
       subtitle = "15 % shell")
```

Plots of residuals vs. expected values look good for the one-step-ahead model.

Are the variances homogeneous across treatments?

```{r}
m3_aug %>%
  ggplot(aes(x = ftreatment, y = residuals)) +
  geom_boxplot() +
  geom_jitter(alpha = 0.2) 

m3_aug %>%
  ggplot(aes(x = rep_trt, y = residuals)) +
  geom_boxplot() +
  geom_jitter(aes(col = ftreatment, shape = ftreatment),alpha = 0.4)  +
  geom_hline(yintercept = 0, linetype = 2, size = 1.5, alpha = 0.5) +
  coord_flip() +
  labs(title = "Residuals for ML estimated model",
       col = "treatment", shape = "treatment",
       x = "treatment x replicate")

m3_aug %>%
  group_by(ftreatment) %>%
  mutate(resid_var = var(residuals)) %>%
  slice(1) %>%
  summarize(resid_var)

# p_reml_fit <- augment(pop_trt_reml, weevil) %>% rename("residuals" = .resid, "fitted" = .fitted)
# p_reml_fit %>%
#   ggplot(aes(x = rep_trt, y = residuals)) +
#   geom_boxplot() +
#   geom_jitter(aes(col = ftreatment),alpha = 0.2)  +
#   geom_hline(yintercept = 0, linetype = 2, size = 1.5, alpha = 0.5) +
#   coord_flip()

```


But is there any autocorrelation in residuals? Lets look visually first, then check using ACF or Ljung-Box tests.

```{r}
m3_aug %>%
  filter(ftreatment == 0) %>%
  ggplot(aes(x = days, y = residuals)) +
  geom_point() + 
  geom_smooth() +
  geom_hline(yintercept = 0, linetype = 2) +
  facet_wrap(~replicate) +
  labs(title = "Residual plot for one-step-ahead model",
       subtitle = "0 % shell")

m3_aug %>%
  filter(ftreatment == 0.05) %>%
  ggplot(aes(x = days, y = residuals)) +
  geom_point() + 
  geom_smooth() +
  geom_hline(yintercept = 0, linetype = 2) +
  facet_wrap(~replicate) +
  labs(title = "Residual plot for one-step-ahead model",
       subtitle = "5 % shell")

m3_aug %>%
  filter(ftreatment == 0.1) %>%
  ggplot(aes(x = days, y = residuals)) +
  geom_point() + 
  geom_smooth() +
  geom_hline(yintercept = 0, linetype = 2) +
  facet_wrap(~replicate) +
  labs(title = "Residual plot for one-step-ahead model",
       subtitle = "10 % shell")

m3_aug %>%
  filter(ftreatment == 0.15) %>%
  ggplot(aes(x = days, y = residuals)) +
  geom_point() + 
  geom_smooth() +
  geom_hline(yintercept = 0, linetype = 2) +
  facet_wrap(~replicate) +
  labs(title = "Residual plot for one-step-ahead model",
       subtitle = "15 % shell")
```

# References {-}

<div id="refs"></div>

```{r}
knitr::knit_exit()
```


# More plots

```{r}
# increments for x and y axis
inc_total <- 5
inc_days <- 50 

# get max days and total, each rounded to the nearest value of inc_*
spark_lims <- 
  full_df %>% 
  select(days, total) %>% 
  summarise(max_days = ceiling(max(days)/inc_days)*inc_days, 
            max_total = ceiling(max(total)/inc_total) * inc_total )

spark_list <- lapply(seq_along(pct_peanut_shells),
                     function(x)
                       full_df %>%
  filter(treatment == pct_peanut_shells[x]) %>%
  ggplot(aes(x = days, y = total)) +
  geom_line() +
  scale_y_continuous(breaks = seq(0, spark_lims$max_total, by = 2*inc_total),
                     limits = c(0, spark_lims$max_total)) +
  scale_x_continuous(breaks = seq(0, spark_lims$max_days, by = 2*inc_days),
                     limits = c(0, spark_lims$max_days)) +
  labs(title = paste0(pct_peanut_shells[x]*100, " % peanut shell in food pellets")) +
  facet_wrap(~replicate))

# 0 % peanut shells
spark_list[[1]]
```

```{r}
spark_list[[3]]
```

```{r}
spark_list[[4]]
```

```{r}
spark_list[[5]]
```

```{r extinction_table}
weevil %>%
  group_by(treatment, replicate) %>%
  slice(1) %>%
  summarise(last_day) %>%
  filter(!is.na(last_day)) %>%
  arrange(treatment, replicate) %>%
  knitr::kable()
```

### log(next_abundance + 1) vs log(abundance + 1)

```{r plot_log_next_pop, fig.show="hold", out.width="50%"}
weevil %>%
  ggplot(aes(x = l_total, y = l_next_total)) +
  geom_point(aes(col = as.factor(replicate)), alpha = 0.4) +
  geom_smooth(method = "lm") +
  facet_wrap(~treatment) + theme(legend.position = "n")

weevil %>%
  ggplot(aes(x = l_total, y = l_next_total)) +
  geom_point(alpha = 0.4) +
  geom_smooth(method = "lm") +
  facet_grid(ftreatment ~ replicate)
```